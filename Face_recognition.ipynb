{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face regonistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this OpenCV with Python tutorial, we're going to cover some basic operations with video and webcams. Aside from the beginning lines, handling frames from a video is identical to handling for images. Let's show some examples:\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "First, we import numpy and cv2, nothing fancy there. Next, we cay cap = cv2.VideoCapture(0). This will return video from the first webcam on your computer. \n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "This code initiates an infinite loop (to be broken later by a break statement), where we have ret and frame being defined as the cap.read(). Basically, ret is a boolean regarding whether or not there was a return at all, at the frame is each frame that is returned. If there is no frame, you wont get an error, you will get None.\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "Here, we define a new variable, gray, as the frame, converted to gray. Notice this says BGR2GRAY. It is important to note that OpenCV reads colors as BGR (Blue Green Red), where most computer applications read as RGB (Red Green Blue). Remember this.\n",
    "\n",
    "    cv2.imshow('frame',gray)\n",
    "Notice that, despite being a video stream, we still use imshow. Here, we're showing the converted-to-gray feed. If you wish to show both at the same time, you can do imshow for the original frame, and imshow for the gray and two windows will appear.\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "This statement just runs once per frame. Basically, if we get a key, and that key is a q, we will exit the while loop with a break, which then runs:\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "This releases the webcam, then closes all of the imshow() windows.\n",
    "\n",
    "In some cases, you may actually want to record, and save the recording to a new file. Here's an example of doing this on Windows:\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "Mainly to note here is the codec being used, and the output information defined before the while loop. Then, within the while loop, we use out.write() to output the frame. Finally, outside the while loop, after we release our webcam, we also release the out.\n",
    "\n",
    "Great, so now we know how to operate with both images and video. If you do not have a webcam, you can follow along the rest of the tutorial with either an image, or even a video. If you wish to use a video, rather than a webcam, within the feed, you specify a file path for a video instead of a camera number.\n",
    "\n",
    "\n",
    " \n",
    "Now that we can work with sources, let's show how we can go about drawing things. Earlier, you were shown that you could use Matplotlib to graph on top of your images, but Matplotlib isn't really meant for this purpose, especially not with video feeds. Luckily, OpenCV comes with some great tools to help us draw and mark up our feeds in real time, which is what we'll be discussing in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Use cv2. VideoCapture( ) to get a video capture object for the camera. Set up an infinite while loop\n",
    "# and use the read() method to read the frames using the above created object. Use cv2.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#We will learn how the Haar cascade object detection works.\n",
    "# We will see the basics of face detection and eye detection using the Haar Feature-based Cascade Classifiers\n",
    "# We will use the cv::CascadeClassifier class to detect objects in a video stream. Particularly, we will use the functions:\n",
    "# cv::CascadeClassifier::load to load a .xml classifier file. It can be either a Haar or a LBP classifier\n",
    "# cv::CascadeClassifier::detectMultiScale to perform the detection.\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "while True:\n",
    "    ##this read two values one boolean and one frame\n",
    "    ret,frame = cap.read()\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if ret == False:\n",
    "        contnue\n",
    "                                                   #scaling factor #NOofneigh\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,10,0),4)\n",
    "    cv2.imshow(\"Video Frame\", frame)\n",
    "    cv2.imshow(\"Video gray Frame\", gray_frame)\n",
    "    #wait fot user input -q , then you will stop the loop\n",
    "    #here 1 in wait key means program will wait for 1 ms in\n",
    "    #ord returns the ascii vale\n",
    "    #cv2.waitkey returns a 32 bit integer 0xff is a no which have 8 1s so the and of a 32 bit no with 81s give effectively\n",
    "    ##the last 8 bit numbers  so we are converting a 32 bit no with 8 bit no and then comparing with the ascii value\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
